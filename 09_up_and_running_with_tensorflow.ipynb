{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chapter 9 â€“ Up and running with TensorFlow**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_This notebook contains all the sample code and solutions to the exercises in chapter 9._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's make sure this notebook works well in both python 2 and 3, import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "# avoid a default graph containing many duplicate nodes.\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"tensorflow\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and running a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "x = tf.Variable(3, name=\"x\")\n",
    "y = tf.Variable(4, name=\"y\")\n",
    "f = x*x*y + y + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_1:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "# session takes are of placing ops onto devices(CPUs,GPUs) and holds all the variable values\n",
    "sess = tf.Session()\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "result = sess.run(f)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = f.eval()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inial all variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result = f.eval()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "#auto set itself as default session\n",
    "sess = tf.InteractiveSession()\n",
    "init.run()\n",
    "result = f.eval()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# need to call close() manually\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Managing graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "x1 = tf.Variable(1)\n",
    "x1.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    x2 = tf.Variable(2)\n",
    "\n",
    "x2.graph is graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tensorflow.python.framework.ops.Graph at 0x10b64c590>,\n",
       " <tensorflow.python.framework.ops.Graph at 0x102d52a50>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.graph, tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "w = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(y.eval())  # 10\n",
    "    print(z.eval())  # 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# eval together, more efficient\n",
    "with tf.Session() as sess:\n",
    "    y_val, z_val = sess.run([y, z])\n",
    "    print(y_val)  # 10\n",
    "    print(z_val)  # 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Normal Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /Users/wangzhiguo/scikit_learn_data\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]\n",
    "\n",
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -3.74651413e+01],\n",
       "       [  4.35734153e-01],\n",
       "       [  9.33829229e-03],\n",
       "       [ -1.06622010e-01],\n",
       "       [  6.44106984e-01],\n",
       "       [ -4.25131839e-06],\n",
       "       [ -3.77322501e-03],\n",
       "       [ -4.26648885e-01],\n",
       "       [ -4.40514028e-01]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare with pure NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -3.69419202e+01]\n",
      " [  4.36693293e-01]\n",
      " [  9.43577803e-03]\n",
      " [ -1.07322041e-01]\n",
      " [  6.45065694e-01]\n",
      " [ -3.97638942e-06]\n",
      " [ -3.78654266e-03]\n",
      " [ -4.21314378e-01]\n",
      " [ -4.34513755e-01]]\n"
     ]
    }
   ],
   "source": [
    "X = housing_data_plus_bias\n",
    "y = housing.target.reshape(-1, 1)\n",
    "theta_numpy = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "\n",
    "print(theta_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare with Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -3.69419202e+01]\n",
      " [  4.36693293e-01]\n",
      " [  9.43577803e-03]\n",
      " [ -1.07322041e-01]\n",
      " [  6.45065694e-01]\n",
      " [ -3.97638942e-06]\n",
      " [ -3.78654265e-03]\n",
      " [ -4.21314378e-01]\n",
      " [ -4.34513755e-01]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/scipy/linalg/basic.py:1018: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(housing.data, housing.target.reshape(-1, 1))\n",
    "\n",
    "print(np.r_[lin_reg.intercept_.reshape(-1, 1), lin_reg.coef_.T])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Descent requires scaling the feature vectors first. We could do this using TF, but let's just use Scikit-Learn for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_housing_data = scaler.fit_transform(housing.data)\n",
    "scaled_housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.00000000e+00   6.60969987e-17   5.50808322e-18   6.60969987e-17\n",
      "  -1.06030602e-16  -1.10161664e-17   3.44255201e-18  -1.07958431e-15\n",
      "  -8.52651283e-15]\n",
      "[ 0.38915536  0.36424355  0.5116157  ..., -0.06612179 -0.06360587\n",
      "  0.01359031]\n",
      "0.111111111111\n",
      "(20640, 9)\n"
     ]
    }
   ],
   "source": [
    "print(scaled_housing_data_plus_bias.mean(axis=0))\n",
    "print(scaled_housing_data_plus_bias.mean(axis=1))\n",
    "print(scaled_housing_data_plus_bias.mean())\n",
    "print(scaled_housing_data_plus_bias.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually computing the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 9.16154\n",
      "Epoch 100 MSE = 0.714501\n",
      "Epoch 200 MSE = 0.566705\n",
      "Epoch 300 MSE = 0.555572\n",
      "Epoch 400 MSE = 0.548812\n",
      "Epoch 500 MSE = 0.543636\n",
      "Epoch 600 MSE = 0.539629\n",
      "Epoch 700 MSE = 0.536509\n",
      "Epoch 800 MSE = 0.534068\n",
      "Epoch 900 MSE = 0.532147\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "\n",
    "# 1.\n",
    "# gradients = 2/m * tf.matmul(tf.transpose(X), error)\n",
    "\n",
    "# 2. more efficienty, use autodiff to reuse previous results\n",
    "#gradients = tf.gradients(mse, [theta])[0]\n",
    "#training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "# 3. more compact, use GradientDescentOptimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "# 4. or use MomentumOptimizer\n",
    "# optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9)\n",
    "    \n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.06855249],\n",
       "       [ 0.88740271],\n",
       "       [ 0.14401658],\n",
       "       [-0.34770882],\n",
       "       [ 0.36178368],\n",
       "       [ 0.00393811],\n",
       "       [-0.04269556],\n",
       "       [-0.66145277],\n",
       "       [-0.6375277 ]], dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How could you find the partial derivatives of the following function with regards to `a` and `b`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_func(a, b):\n",
    "    z = 0\n",
    "    for i in range(100):\n",
    "        z = a * np.cos(z + i) + z * np.sin(b - i)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.21253923284754916"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_func(0.2, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "a = tf.Variable(0.2, name=\"a\")\n",
    "b = tf.Variable(0.3, name=\"b\")\n",
    "z = tf.constant(0.0, name=\"z0\")\n",
    "for i in range(100):\n",
    "    z = a * tf.cos(z + i) + z * tf.sin(b - i)\n",
    "\n",
    "grads = tf.gradients(z, [a, b])\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the function at $a=0.2$ and $b=0.3$, and the partial derivatives at that point with regards to $a$ and with regards to $b$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.212537\n",
      "[-1.1388494, 0.19671395]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    print(z.eval())\n",
    "    print(sess.run(grads))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feeding data to the training algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placeholder nodes\n",
    "\n",
    "* Placeholders just hold information about the type and shape of the tensor they represent, but they have no value.\n",
    "* Placeholders are typically used to feed training or test data to TensorFlow during the execution phase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.  7.  8.]]\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "A = tf.placeholder(tf.float32, shape=(None, 3))\n",
    "B = A + 5\n",
    "with tf.Session() as sess:\n",
    "    B_val_1 = B.eval(feed_dict={A: [[1, 2, 3]]})\n",
    "    B_val_2 = B.eval(feed_dict={A: [[4, 5, 6], [7, 8, 9]]})\n",
    "\n",
    "print(B_val_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9.  10.  11.]\n",
      " [ 12.  13.  14.]]\n"
     ]
    }
   ],
   "source": [
    "print(B_val_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "# log for tensorboard view\n",
    "mse_summary = tf.summary.scalar('MSE', mse)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "# SGD\n",
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "def fetch_batches(all_indices):\n",
    "    # np.random.shuffle(all_indices)\n",
    "    lst = np.random.permutation(m)\n",
    "    for i in range(n_batches):\n",
    "        indices = all_indices[lst[batch_size*i:batch_size*(i+1)]]\n",
    "        X_batch = scaled_housing_data_plus_bias[indices] # not shown\n",
    "        y_batch = housing.target.reshape(-1, 1)[indices] # not shown\n",
    "        yield X_batch, y_batch\n",
    "\n",
    "all_indices = range(m)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 6 3 4 5 9 0 8 7]\n",
      "[1 2 6]\n",
      "[3 4 5]\n",
      "[9 0 8]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "lst = np.random.permutation(10)\n",
    "print(lst)\n",
    "for i in range(len(lst)/3):\n",
    "    print lst[3*i:3*(i+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 0.446319\n",
      "Epoch 1 MSE = 0.889004\n",
      "Epoch 2 MSE = 0.445557\n",
      "Epoch 3 MSE = 0.638093\n",
      "Epoch 4 MSE = 0.409967\n",
      "Epoch 5 MSE = 0.67544\n",
      "Epoch 6 MSE = 0.692455\n",
      "Epoch 7 MSE = 0.770845\n",
      "Epoch 8 MSE = 0.447256\n",
      "Epoch 9 MSE = 0.369898\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Saving and restoring a model\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)    \n",
    "    step = 0\n",
    "    for epoch in range(n_epochs):\n",
    "        np.random.shuffle(all_indices)\n",
    "        for X_batch, y_batch in fetch_batches(all_indices):\n",
    "            # feed_dict to training model\n",
    "            mse_val, mse_str, _ = sess.run([mse, mse_summary, training_op], feed_dict={X: X_batch, y: y_batch})\n",
    "            file_writer.add_summary(mse_str, step)\n",
    "            step += 1\n",
    "                \n",
    "        print(\"Epoch\", epoch, \"MSE =\", mse_val) \n",
    "        save_path = saver.save(sess, \"/tmp/my_model.ckpt\")\n",
    "\n",
    "    best_theta = theta.eval()\n",
    "    save_path = saver.save(sess, \"/tmp/my_model_final.ckpt\")\n",
    "    \n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.06792331],\n",
       "       [ 0.84182072],\n",
       "       [ 0.12187602],\n",
       "       [-0.2643716 ],\n",
       "       [ 0.37408483],\n",
       "       [-0.0037177 ],\n",
       "       [-0.0980344 ],\n",
       "       [-0.8128581 ],\n",
       "       [-0.80013651]], dtype=float32)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"/tmp/my_model_final.ckpt\")  # this restores the graph's state\n",
    "    best_theta_restored = theta.eval()\n",
    "    \n",
    "assert np.allclose(best_theta, best_theta_restored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to have a saver that loads and restores `theta` with a different name, such as `\"weights\"`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver({\"weights\": theta})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default the saver also saves the graph structure itself in a second file with the extension `.meta`. You can use the function `tf.train.import_meta_graph()` to restore the graph structure. This function loads the graph into the default graph and returns a `Saver` that can then be used to restore the graph state (i.e., the variable values):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset_graph()\n",
    "# notice that we start with an empty graph.\n",
    "\n",
    "saver = tf.train.import_meta_graph(\"/tmp/my_model_final.ckpt.meta\")  # this loads the graph structure\n",
    "theta = tf.get_default_graph().get_tensor_by_name(\"theta:0\") # not shown in the book\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"/tmp/my_model_final.ckpt\")  # this restores the graph's state\n",
    "    best_theta_restored = theta.eval() # not shown in the book\n",
    "\n",
    "np.allclose(best_theta, best_theta_restored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that you can import a pretrained model without having to have the corresponding Python code to build the graph. This is very handy when you keep tweaking and saving your model: you can load a previously saved model without having to search for the version of the code that built it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the graph\n",
    "## inside Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = b\"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.374540118847&quot;).pbtxt = 'node {\\n  name: &quot;X&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 20640\\n          }\\n          dim {\\n            size: 9\\n          }\\n        }\\n        tensor_content: &quot;<stripped 743040 bytes>&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 20640\\n          }\\n          dim {\\n            size: 1\\n          }\\n        }\\n        tensor_content: &quot;<stripped 82560 bytes>&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\t\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;random_uniform/max&quot;\\n  input: &quot;random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;random_uniform/RandomUniform&quot;\\n  input: &quot;random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;random_uniform/mul&quot;\\n  input: &quot;random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;theta&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 9\\n        }\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;theta/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;theta&quot;\\n  input: &quot;random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@theta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;theta/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;theta&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@theta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;predictions&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;theta/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;predictions&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Square&quot;\\n  op: &quot;Square&quot;\\n  input: &quot;sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;mse&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;Square&quot;\\n  input: &quot;Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape&quot;\\n  input: &quot;gradients/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Fill&quot;\\n  input: &quot;gradients/mse_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Tile/multiples&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\240P\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;gradients/mse_grad/Reshape&quot;\\n  input: &quot;gradients/mse_grad/Tile/multiples&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\240P\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/mse_grad/Shape&quot;\\n  input: &quot;gradients/mse_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/mse_grad/Shape_1&quot;\\n  input: &quot;gradients/mse_grad/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;gradients/mse_grad/Prod_1&quot;\\n  input: &quot;gradients/mse_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;gradients/mse_grad/Prod&quot;\\n  input: &quot;gradients/mse_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;gradients/mse_grad/floordiv&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;gradients/mse_grad/Tile&quot;\\n  input: &quot;gradients/mse_grad/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Square_grad/mul/x&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/mse_grad/truediv&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 2.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Square_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/Square_grad/mul/x&quot;\\n  input: &quot;sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Square_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/mse_grad/truediv&quot;\\n  input: &quot;gradients/Square_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\240P\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\240P\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/sub_grad/Shape&quot;\\n  input: &quot;gradients/sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/Square_grad/mul_1&quot;\\n  input: &quot;gradients/sub_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/sub_grad/Sum&quot;\\n  input: &quot;gradients/sub_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/Square_grad/mul_1&quot;\\n  input: &quot;gradients/sub_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;gradients/sub_grad/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/sub_grad/Neg&quot;\\n  input: &quot;gradients/sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/sub_grad/Reshape&quot;\\n  input: &quot;^gradients/sub_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/sub_grad/Reshape&quot;\\n  input: &quot;^gradients/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/sub_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/sub_grad/Reshape_1&quot;\\n  input: &quot;^gradients/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/sub_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/predictions_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/sub_grad/tuple/control_dependency&quot;\\n  input: &quot;theta/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/predictions_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;gradients/sub_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/predictions_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/predictions_grad/MatMul&quot;\\n  input: &quot;^gradients/predictions_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/predictions_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/predictions_grad/MatMul&quot;\\n  input: &quot;^gradients/predictions_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/predictions_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/predictions_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/predictions_grad/MatMul_1&quot;\\n  input: &quot;^gradients/predictions_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/predictions_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/learning_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.00999999977648\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_theta/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;theta&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;gradients/predictions_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@theta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^GradientDescent/update_theta/ApplyGradientDescent&quot;\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^theta/Assign&quot;\\n}\\nnode {\\n  name: &quot;save/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;model&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;theta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2&quot;\\n  op: &quot;SaveV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/SaveV2/tensor_names&quot;\\n  input: &quot;save/SaveV2/shape_and_slices&quot;\\n  input: &quot;theta&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;^save/SaveV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@save/Const&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;theta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2/tensor_names&quot;\\n  input: &quot;save/RestoreV2/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;theta&quot;\\n  input: &quot;save/RestoreV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@theta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/restore_all&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^save/Assign&quot;\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.374540118847&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name scopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\") as scope:\n",
    "    error = y_pred - y\n",
    "    mse = tf.reduce_mean(tf.square(error), name=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "mse_summary = tf.summary.scalar('MSE', mse)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best theta:\n",
      "[[ 2.07033372]\n",
      " [ 0.86371452]\n",
      " [ 0.12255151]\n",
      " [-0.31211874]\n",
      " [ 0.38510373]\n",
      " [ 0.00434168]\n",
      " [-0.01232954]\n",
      " [-0.83376896]\n",
      " [-0.80304712]]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            if batch_index % 10 == 0:\n",
    "                summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "                step = epoch * n_batches + batch_index\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "\n",
    "    best_theta = theta.eval()\n",
    "\n",
    "file_writer.flush()\n",
    "file_writer.close()\n",
    "print(\"Best theta:\")\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss/sub loss/mse\n"
     ]
    }
   ],
   "source": [
    "# now ops are prefixed with \"loss/\"\n",
    "print(error.op.name, mse.op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "a_1\n",
      "param/a\n",
      "param_1/a\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "a1 = tf.Variable(0, name=\"a\")      # name == \"a\"\n",
    "a2 = tf.Variable(0, name=\"a\")      # name == \"a_1\"\n",
    "\n",
    "with tf.name_scope(\"param\"):       # name == \"param\"\n",
    "    a3 = tf.Variable(0, name=\"a\")  # name == \"param/a\"\n",
    "\n",
    "with tf.name_scope(\"param\"):       # name == \"param_1\"\n",
    "    a4 = tf.Variable(0, name=\"a\")  # name == \"param_1/a\"\n",
    "\n",
    "for node in (a1, a2, a3, a4):\n",
    "    print(node.op.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An ugly flat code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal((n_features, 1)), name=\"weights1\")\n",
    "w2 = tf.Variable(tf.random_normal((n_features, 1)), name=\"weights2\")\n",
    "b1 = tf.Variable(0.0, name=\"bias1\")\n",
    "b2 = tf.Variable(0.0, name=\"bias2\")\n",
    "\n",
    "z1 = tf.add(tf.matmul(X, w1), b1, name=\"z1\")\n",
    "z2 = tf.add(tf.matmul(X, w2), b2, name=\"z2\")\n",
    "\n",
    "relu1 = tf.maximum(z1, 0., name=\"relu1\")\n",
    "relu2 = tf.maximum(z1, 0., name=\"relu2\")  # Oops, cut&paste error! Did you spot it?\n",
    "\n",
    "output = tf.add(relu1, relu2, name=\"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better, using a function to build the ReLUs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "def relu(X):\n",
    "    w_shape = (int(X.get_shape()[1]), 1)\n",
    "    w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")\n",
    "    b = tf.Variable(0.0, name=\"bias\")\n",
    "    z = tf.add(tf.matmul(X, w), b, name=\"z\")\n",
    "    return tf.maximum(z, 0., name=\"relu\")\n",
    "\n",
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "relus = [relu(X) for i in range(5)]\n",
    "output = tf.add_n(relus, name=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_writer = tf.summary.FileWriter(\"logs/relu1\", tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even better using name scopes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "def relu(X):\n",
    "    with tf.name_scope(\"relu\"):\n",
    "        w_shape = (int(X.get_shape()[1]), 1)                          # not shown in the book\n",
    "        w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")    # not shown\n",
    "        b = tf.Variable(0.0, name=\"bias\")                             # not shown\n",
    "        z = tf.add(tf.matmul(X, w), b, name=\"z\")                      # not shown\n",
    "        return tf.maximum(z, 0., name=\"max\")                          # not shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "relus = [relu(X) for i in range(5)]\n",
    "output = tf.add_n(relus, name=\"output\")\n",
    "\n",
    "file_writer = tf.summary.FileWriter(\"logs/relu2\", tf.get_default_graph())\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharing Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sharing a `threshold` variable the classic way, by defining it outside of the `relu()` function then passing it as a parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "def relu(X, threshold):\n",
    "    with tf.name_scope(\"relu\"):\n",
    "        w_shape = (int(X.get_shape()[1]), 1)                        # not shown in the book\n",
    "        w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")  # not shown\n",
    "        b = tf.Variable(0.0, name=\"bias\")                           # not shown\n",
    "        z = tf.add(tf.matmul(X, w), b, name=\"z\")                    # not shown\n",
    "        return tf.maximum(z, threshold, name=\"max\")\n",
    "\n",
    "threshold = tf.Variable(0.0, name=\"threshold\")\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "relus = [relu(X, threshold) for i in range(5)]\n",
    "output = tf.add_n(relus, name=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "def relu(X):\n",
    "    with tf.name_scope(\"relu\"):\n",
    "        if not hasattr(relu, \"threshold\"):\n",
    "            relu.threshold = tf.Variable(0.0, name=\"threshold\")\n",
    "        w_shape = int(X.get_shape()[1]), 1                          # not shown in the book\n",
    "        w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")  # not shown\n",
    "        b = tf.Variable(0.0, name=\"bias\")                           # not shown\n",
    "        z = tf.add(tf.matmul(X, w), b, name=\"z\")                    # not shown\n",
    "        return tf.maximum(z, relu.threshold, name=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "relus = [relu(X) for i in range(5)]\n",
    "output = tf.add_n(relus, name=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "with tf.variable_scope(\"relu\"):\n",
    "    threshold = tf.get_variable(\"threshold\", shape=(),\n",
    "                                initializer=tf.constant_initializer(0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"relu\", reuse=True):\n",
    "    threshold = tf.get_variable(\"threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"relu\") as scope:\n",
    "    scope.reuse_variables()\n",
    "    threshold = tf.get_variable(\"threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "def relu(X):\n",
    "    with tf.variable_scope(\"relu\", reuse=True):\n",
    "        threshold = tf.get_variable(\"threshold\")\n",
    "        w_shape = int(X.get_shape()[1]), 1                          # not shown\n",
    "        w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")  # not shown\n",
    "        b = tf.Variable(0.0, name=\"bias\")                           # not shown\n",
    "        z = tf.add(tf.matmul(X, w), b, name=\"z\")                    # not shown\n",
    "        return tf.maximum(z, threshold, name=\"max\")\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "with tf.variable_scope(\"relu\"):\n",
    "    threshold = tf.get_variable(\"threshold\", shape=(),\n",
    "                                initializer=tf.constant_initializer(0.0))\n",
    "relus = [relu(X) for relu_index in range(5)]\n",
    "output = tf.add_n(relus, name=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer = tf.summary.FileWriter(\"logs/relu6\", tf.get_default_graph())\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "def relu(X):\n",
    "    with tf.variable_scope(\"relu\"):\n",
    "        threshold = tf.get_variable(\"threshold\", shape=(), initializer=tf.constant_initializer(0.0))\n",
    "        w_shape = (int(X.get_shape()[1]), 1)\n",
    "        w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")\n",
    "        b = tf.Variable(0.0, name=\"bias\")\n",
    "        z = tf.add(tf.matmul(X, w), b, name=\"z\")\n",
    "        return tf.maximum(z, threshold, name=\"max\")\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "with tf.variable_scope(\"\", default_name=\"\") as scope:\n",
    "    first_relu = relu(X)     # create the shared variable\n",
    "    scope.reuse_variables()  # then reuse it\n",
    "    relus = [first_relu] + [relu(X) for i in range(4)]\n",
    "output = tf.add_n(relus, name=\"output\")\n",
    "\n",
    "file_writer = tf.summary.FileWriter(\"logs/relu8\", tf.get_default_graph())\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "def relu(X):\n",
    "    threshold = tf.get_variable(\"threshold\", shape=(),\n",
    "                                initializer=tf.constant_initializer(0.0))\n",
    "    w_shape = (int(X.get_shape()[1]), 1)                        # not shown in the book\n",
    "    w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")  # not shown\n",
    "    b = tf.Variable(0.0, name=\"bias\")                           # not shown\n",
    "    z = tf.add(tf.matmul(X, w), b, name=\"z\")                    # not shown\n",
    "    return tf.maximum(z, threshold, name=\"max\")\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "relus = []\n",
    "for relu_index in range(5):\n",
    "    with tf.variable_scope(\"relu\", reuse=(relu_index >= 1)) as scope:\n",
    "        relus.append(relu(X))\n",
    "output = tf.add_n(relus, name=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_writer = tf.summary.FileWriter(\"logs/relu9\", tf.get_default_graph())\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0: my_scope/x\n",
      "x1: my_scope/x_1\n",
      "x2: my_scope/x_2\n",
      "x3: my_scope/x\n",
      "x4: my_scope_1/x\n",
      "x5: my_scope/x\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "with tf.variable_scope(\"my_scope\"):\n",
    "    x0 = tf.get_variable(\"x\", shape=(), initializer=tf.constant_initializer(0.))\n",
    "    x1 = tf.Variable(0., name=\"x\")\n",
    "    x2 = tf.Variable(0., name=\"x\")\n",
    "\n",
    "with tf.variable_scope(\"my_scope\", reuse=True):\n",
    "    x3 = tf.get_variable(\"x\")\n",
    "    x4 = tf.Variable(0., name=\"x\")\n",
    "\n",
    "with tf.variable_scope(\"\", default_name=\"\", reuse=True):\n",
    "    x5 = tf.get_variable(\"my_scope/x\")\n",
    "\n",
    "print(\"x0:\", x0.op.name)\n",
    "print(\"x1:\", x1.op.name)\n",
    "print(\"x2:\", x2.op.name)\n",
    "print(\"x3:\", x3.op.name)\n",
    "print(\"x4:\", x4.op.name)\n",
    "print(\"x5:\", x5.op.name)\n",
    "print(x0 is x3 and x3 is x5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first `variable_scope()` block first creates the shared variable `x0`, named `my_scope/x`. For all operations other than shared variables (including non-shared variables), the variable scope acts like a regular name scope, which is why the two variables `x1` and `x2` have a name with a prefix `my_scope/`. Note however that TensorFlow makes their names unique by adding an index: `my_scope/x_1` and `my_scope/x_2`.\n",
    "\n",
    "The second `variable_scope()` block reuses the shared variables in scope `my_scope`, which is why `x0 is x3`. Once again, for all operations other than shared variables it acts as a named scope, and since it's a separate block from the first one, the name of the scope is made unique by TensorFlow (`my_scope_1`) and thus the variable `x4` is named `my_scope_1/x`.\n",
    "\n",
    "The third block shows another way to get a handle on the shared variable `my_scope/x` by creating a `variable_scope()` at the root scope (whose name is an empty string), then calling `get_variable()` with the full name of the shared variable (i.e. `\"my_scope/x\"`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Do' 'you' 'want' 'some' 'caf\\xc3\\xa9?']\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "text = np.array(\"Do you want some cafÃ©?\".split())\n",
    "text_tensor = tf.constant(text)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(text_tensor.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a Home-Made Computation Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(x,y) = ((x) * (x)) * (y) + y + 2\n",
      "f(3,4) = 42\n"
     ]
    }
   ],
   "source": [
    "class Const(object):\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "    def evaluate(self):\n",
    "        return self.value\n",
    "    def __str__(self):\n",
    "        return str(self.value)\n",
    "\n",
    "class Var(object):\n",
    "    def __init__(self, init_value, name):\n",
    "        self.value = init_value\n",
    "        self.name = name\n",
    "    def evaluate(self):\n",
    "        return self.value\n",
    "    def __str__(self):\n",
    "        return self.name\n",
    "\n",
    "class BinaryOperator(object):\n",
    "    def __init__(self, a, b):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "\n",
    "class Add(BinaryOperator):\n",
    "    def evaluate(self):\n",
    "        return self.a.evaluate() + self.b.evaluate()\n",
    "    def __str__(self):\n",
    "        return \"{} + {}\".format(self.a, self.b)\n",
    "\n",
    "class Mul(BinaryOperator):\n",
    "    def evaluate(self):\n",
    "        return self.a.evaluate() * self.b.evaluate()\n",
    "    def __str__(self):\n",
    "        return \"({}) * ({})\".format(self.a, self.b)\n",
    "\n",
    "x = Var(3, name=\"x\")\n",
    "y = Var(4, name=\"y\")\n",
    "f = Add(Mul(Mul(x, x), y), Add(y, Const(2))) # f(x,y) = xÂ²y + y + 2\n",
    "print(\"f(x,y) =\", f)\n",
    "print(\"f(3,4) =\", f.evaluate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing gradients\n",
    "### Mathematical differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df/dx(3,4) = 24\n",
      "df/dy(3,4) = 10\n"
     ]
    }
   ],
   "source": [
    "df_dx = Mul(Const(2), Mul(x, y))  # df/dx = 2xy\n",
    "df_dy = Add(Mul(x, x), Const(1))  # df/dy = xÂ² + 1\n",
    "print(\"df/dx(3,4) =\", df_dx.evaluate())\n",
    "print(\"df/dy(3,4) =\", df_dy.evaluate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df/dx(3,4) = 24.0004\n",
      "df/dy(3,4) = 10.0\n"
     ]
    }
   ],
   "source": [
    "def gradients(func, vars_list, eps=0.0001):\n",
    "    partial_derivatives = []\n",
    "    base_func_eval = func.evaluate()\n",
    "    for var in vars_list:\n",
    "        original_value = var.value\n",
    "        var.value = var.value + eps\n",
    "        tweaked_func_eval = func.evaluate()\n",
    "        var.value = original_value\n",
    "        derivative = (tweaked_func_eval - base_func_eval) / eps\n",
    "        partial_derivatives.append(derivative)\n",
    "    return partial_derivatives\n",
    "\n",
    "df_dx, df_dy = gradients(f, [x, y])\n",
    "print(\"df/dx(3,4) =\", df_dx)\n",
    "print(\"df/dy(3,4) =\", df_dy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symbolic differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df/dx(3,4) = 24.0\n",
      "df/dy(3,4) = 10.0\n"
     ]
    }
   ],
   "source": [
    "Const.derive = lambda self, var: Const(0)\n",
    "Var.derive = lambda self, var: Const(1) if self is var else Const(0)\n",
    "Add.derive = lambda self, var: Add(self.a.derive(var), self.b.derive(var))\n",
    "Mul.derive = lambda self, var: Add(Mul(self.a, self.b.derive(var)), Mul(self.a.derive(var), self.b))\n",
    "\n",
    "x = Var(3.0, name=\"x\")\n",
    "y = Var(4.0, name=\"y\")\n",
    "f = Add(Mul(Mul(x, x), y), Add(y, Const(2))) # f(x,y) = xÂ²y + y + 2\n",
    "\n",
    "df_dx = f.derive(x)  # 2xy\n",
    "df_dy = f.derive(y)  # xÂ² + 1\n",
    "print(\"df/dx(3,4) =\", df_dx.evaluate())\n",
    "print(\"df/dy(3,4) =\", df_dy.evaluate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic differentiation (autodiff) â€“ forward mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encoding: utf-8\n",
    "class DualNumber(object):\n",
    "    def __init__(self, value=0.0, eps=0.0):\n",
    "        self.value = value\n",
    "        self.eps = eps\n",
    "    def __add__(self, b):\n",
    "        return DualNumber(self.value + self.to_dual(b).value,\n",
    "                          self.eps + self.to_dual(b).eps)\n",
    "    def __radd__(self, a):\n",
    "        return self.to_dual(a).__add__(self)\n",
    "    def __mul__(self, b):\n",
    "        return DualNumber(self.value * self.to_dual(b).value,\n",
    "                          self.eps * self.to_dual(b).value + self.value * self.to_dual(b).eps)\n",
    "    def __rmul__(self, a):\n",
    "        return self.to_dual(a).__mul__(self)\n",
    "    def __str__(self):\n",
    "        if self.eps:\n",
    "            return \"{:.1f} + {:.1f}e\".format(self.value, self.eps)\n",
    "        else:\n",
    "            return \"{:.1f}\".format(self.value)\n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    @classmethod\n",
    "    def to_dual(cls, n):\n",
    "        if hasattr(n, \"value\"):\n",
    "            return n\n",
    "        else:\n",
    "            return cls(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$3 + (3 + 4 \\epsilon) = 6 + 4\\epsilon$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0 + 4.0e"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3 + DualNumber(3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(3 + 4Îµ)\\times(5 + 7Îµ) = 3 \\times 5 + 3 \\times 7Îµ + 4Îµ \\times 5 + 4Îµ \\times 7Îµ = 15 + 21Îµ + 20Îµ + 28Îµ^2 = 15 + 41Îµ + 28 \\times 0 = 15 + 41Îµ$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.0 + 41.0e"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DualNumber(3, 4) * DualNumber(5, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.0"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.value = DualNumber(3.0)\n",
    "y.value = DualNumber(4.0)\n",
    "\n",
    "f.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.value = DualNumber(3.0, 1.0)  # 3 + Îµ\n",
    "y.value = DualNumber(4.0)       # 4\n",
    "\n",
    "df_dx = f.evaluate().eps\n",
    "\n",
    "x.value = DualNumber(3.0)       # 3\n",
    "y.value = DualNumber(4.0, 1.0)  # 4 + Îµ\n",
    "\n",
    "df_dy = f.evaluate().eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.0"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autodiff â€“ Reverse mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(x,y) = ((x) * (x)) * (y) + y + 2\n",
      "f(3,4) = 42\n",
      "df_dx = 24.0\n",
      "df_dy = 10.0\n"
     ]
    }
   ],
   "source": [
    "class Const(object):\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "    def evaluate(self):\n",
    "        return self.value\n",
    "    def backpropagate(self, gradient):\n",
    "        pass\n",
    "    def __str__(self):\n",
    "        return str(self.value)\n",
    "\n",
    "class Var(object):\n",
    "    def __init__(self, init_value, name):\n",
    "        self.value = init_value\n",
    "        self.name = name\n",
    "        self.gradient = 0\n",
    "    def evaluate(self):\n",
    "        return self.value\n",
    "    def backpropagate(self, gradient):\n",
    "        self.gradient += gradient\n",
    "    def __str__(self):\n",
    "        return self.name\n",
    "\n",
    "class BinaryOperator(object):\n",
    "    def __init__(self, a, b):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "\n",
    "class Add(BinaryOperator):\n",
    "    def evaluate(self):\n",
    "        self.value = self.a.evaluate() + self.b.evaluate()\n",
    "        return self.value\n",
    "    def backpropagate(self, gradient):\n",
    "        self.a.backpropagate(gradient)\n",
    "        self.b.backpropagate(gradient)\n",
    "    def __str__(self):\n",
    "        return \"{} + {}\".format(self.a, self.b)\n",
    "\n",
    "class Mul(BinaryOperator):\n",
    "    def evaluate(self):\n",
    "        self.value = self.a.evaluate() * self.b.evaluate()\n",
    "        return self.value\n",
    "    def backpropagate(self, gradient):\n",
    "        self.a.backpropagate(gradient * self.b.value)\n",
    "        self.b.backpropagate(gradient * self.a.value)\n",
    "    def __str__(self):\n",
    "        return \"({}) * ({})\".format(self.a, self.b)\n",
    "\n",
    "x = Var(3, name=\"x\")\n",
    "y = Var(4, name=\"y\")\n",
    "f = Add(Mul(Mul(x, x), y), Add(y, Const(2))) # f(x,y) = xÂ²y + y + 2\n",
    "\n",
    "result = f.evaluate()\n",
    "f.backpropagate(1.0)\n",
    "\n",
    "print(\"f(x,y) =\", f)\n",
    "print(\"f(3,4) =\", result)\n",
    "print(\"df_dx =\", x.gradient)\n",
    "print(\"df_dy =\", y.gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autodiff â€“ reverse mode (using TensorFlow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42.0, [24.0, 10.0])"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "x = tf.Variable(3., name=\"x\")\n",
    "y = tf.Variable(4., name=\"y\")\n",
    "f = x*x*y + y + 2\n",
    "\n",
    "gradients = tf.gradients(f, [x, y])\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    f_val, gradients_val = sess.run([f, gradients])\n",
    "\n",
    "f_val, gradients_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. to 11."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "See appendix A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Logistic Regression with Mini-Batch Gradient Descent using TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's create the moons dataset using Scikit-Learn's `make_moons()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "m = 1000\n",
    "X_moons, y_moons = make_moons(m, noise=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a peek at the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEFCAYAAAAIZiutAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBQUFBRuUcVBQUFBQsEEZBwUFBQUFG/4fyZ7xfGegVdIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112160250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X_moons[y_moons == 1, 0], X_moons[y_moons == 1, 1], 'go', label=\"Positive\")\n",
    "plt.plot(X_moons[y_moons == 0, 0], X_moons[y_moons == 0, 1], 'r^', label=\"Negative\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must not forget to add an extra bias feature ($x_0 = 1$) to every instance. For this, we just need to add a column full of 1s on the left of the input matrix $\\mathbf{X}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_moons_with_bias = np.c_[np.ones((m, 1)), X_moons]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.05146968,  0.44419863],\n",
       "       [ 1.        ,  1.03201691, -0.41974116],\n",
       "       [ 1.        ,  0.86789186, -0.25482711],\n",
       "       [ 1.        ,  0.288851  , -0.44866862],\n",
       "       [ 1.        , -0.83343911,  0.53505665]])"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_moons_with_bias[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good. Now let's reshape `y_train` to make it a column vector (i.e. a 2D array with a single column):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_moons_column_vector = y_moons.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's split the data into a training set and a test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ratio = 0.2\n",
    "test_size = int(m * test_ratio)\n",
    "X_train = X_moons_with_bias[:-test_size]\n",
    "X_test = X_moons_with_bias[-test_size:]\n",
    "y_train = y_moons_column_vector[:-test_size]\n",
    "y_test = y_moons_column_vector[-test_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now let's create a small function to generate training batches. In this implementation we will just pick random instances from the training set for each batch. This means that a single batch may contain the same instance multiple times, and also a single epoch may not cover all the training instances (in fact it will generally cover only about two thirds of the instances). However, in practice this is not an issue and it simplifies the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_batch(X_train, y_train, batch_size):\n",
    "    rnd_indices = np.random.randint(0, len(X_train), batch_size)\n",
    "    X_batch = X_train[rnd_indices]\n",
    "    y_batch = y_train[rnd_indices]\n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a small batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.68675984, -0.37776263],\n",
       "       [ 1.        ,  0.79170038, -0.51349765],\n",
       "       [ 1.        , -0.77267555,  0.75156907],\n",
       "       [ 1.        ,  0.71607055, -0.51694196],\n",
       "       [ 1.        ,  0.59758054,  0.81803294]])"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch, y_batch = random_batch(X_train, y_train, 5)\n",
    "X_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now that the data is ready to be fed to the model, we need to build that model. Let's start with a simple implementation, then we will add all the bells and whistles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's reset the default graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _moons_ dataset has two input features, since each instance is a point on a plane (i.e., 2-Dimensional):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_inputs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's build the Logistic Regression model. As we saw in chapter 4, this model first computes a weighted sum of the inputs (just like the Linear Regression model), and then it applies the sigmoid function to the result, which gives us the estimated probability for the positive class:\n",
    "\n",
    "$\\hat{p} = h_\\mathbf{\\theta}(\\mathbf{x}) = \\sigma(\\mathbf{\\theta}^T \\cdot \\mathbf{x})$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that $\\mathbf{\\theta}$ is the parameter vector, containing the bias term $\\theta_0$ and the weights $\\theta_1, \\theta_2, \\dots, \\theta_n$. The input vector $\\mathbf{x}$ contains a constant term $x_0 = 1$, as well as all the input features $x_1, x_2, \\dots, x_n$.\n",
    "\n",
    "Since we want to be able to make predictions for multiple instances at a time, we will use an input matrix $\\mathbf{X}$ rather than a single input vector. The $i^{th}$ row will contain the transpose of the $i^{th}$ input vector $(\\mathbf{x}^{(i)})^T$. It is then possible to estimate the probability that each instance belongs to the positive class using the following equation:\n",
    "\n",
    "$ \\hat{\\mathbf{p}} = \\sigma(\\mathbf{X} \\cdot \\mathbf{\\theta})$\n",
    "\n",
    "That's all we need to build the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n_inputs + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "logits = tf.matmul(X, theta, name=\"logits\")\n",
    "\n",
    "y_proba = 1 / (1 + tf.exp(-logits))\n",
    "# In fact, TensorFlow has a nice function tf.sigmoid() that \n",
    "# we can use to simplify the last line of the previous code:\n",
    "y_proba = tf.sigmoid(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw in chapter 4, the log loss is a good cost function to use for Logistic Regression:\n",
    "\n",
    "$J(\\mathbf{\\theta}) = -\\dfrac{1}{m} \\sum\\limits_{i=1}^{m}{\\left[ y^{(i)} log\\left(\\hat{p}^{(i)}\\right) + (1 - y^{(i)}) log\\left(1 - \\hat{p}^{(i)}\\right)\\right]}$\n",
    "\n",
    "One option is to implement it ourselves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-7  # to avoid an overflow when computing the log\n",
    "loss = -tf.reduce_mean(y * tf.log(y_proba + epsilon) + (1 - y) * tf.log(1 - y_proba + epsilon))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we might as well use TensorFlow's `tf.losses.log_loss()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.losses.log_loss(y, y_proba)  # uses epsilon = 1e-7 by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest is pretty standard: let's create the optimizer and tell it to minimize the cost function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All we need now (in this minimal version) is the variable initializer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we are ready to train the model and use it for predictions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's really nothing special about this code, it's virtually the same as the one we used earlier for Linear Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \tLoss: 0.792602\n",
      "Epoch: 100 \tLoss: 0.343463\n",
      "Epoch: 200 \tLoss: 0.30754\n",
      "Epoch: 300 \tLoss: 0.292889\n",
      "Epoch: 400 \tLoss: 0.285336\n",
      "Epoch: 500 \tLoss: 0.280478\n",
      "Epoch: 600 \tLoss: 0.278083\n",
      "Epoch: 700 \tLoss: 0.276154\n",
      "Epoch: 800 \tLoss: 0.27552\n",
      "Epoch: 900 \tLoss: 0.274912\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 50\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = random_batch(X_train, y_train, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val = loss.eval({X: X_test, y: y_test})\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch:\", epoch, \"\\tLoss:\", loss_val)\n",
    "\n",
    "    y_proba_val = y_proba.eval(feed_dict={X: X_test, y: y_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: we don't use the epoch number when generating batches, so we could just have a single `for` loop rather than 2 nested `for` loops, but it's convenient to think of training time in terms of number of epochs (i.e., roughly the number of times the algorithm went through the training set)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each instance in the test set, `y_proba_val` contains the estimated probability that it belongs to the positive class, according to the model. For example, here are the first 5 estimated probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.54895616],\n",
       "       [ 0.70724374],\n",
       "       [ 0.51900262],\n",
       "       [ 0.9911136 ],\n",
       "       [ 0.50859046]], dtype=float32)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba_val[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To classify each instance, we can go for maximum likelihood: classify as positive any instance whose estimated probability is greater or equal to 0.5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]], dtype=bool)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = (y_proba_val >= 0.5)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the use case, you may want to choose a different threshold than 0.5: make it higher if you want high precision (but lower recall), and make it lower if you want high recall (but lower precision). See chapter 3 for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the model's precision and recall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86274509803921573"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88888888888888884"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot these predictions to see what they look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEFCAYAAAAIZiutAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4/8D9om5NYntsq0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11294d1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_idx = y_pred.reshape(-1) # a 1D array rather than a column vector\n",
    "plt.plot(X_test[y_pred_idx, 1], X_test[y_pred_idx, 2], 'go', label=\"Positive\")\n",
    "plt.plot(X_test[~y_pred_idx, 1], X_test[~y_pred_idx, 2], 'r^', label=\"Negative\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that looks pretty bad, doesn't it? But let's not forget that the Logistic Regression model has a linear decision boundary, so this is actually close to the best we can do with this model (unless we add more features, as we will show in a second)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's start over, but this time we will add all the bells and whistles, as listed in the exercise:\n",
    "* Define the graph within a `logistic_regression()` function that can be reused easily.\n",
    "* Save checkpoints using a `Saver` at regular intervals during training, and save the final model at the end of training.\n",
    "* Restore the last checkpoint upon startup if training was interrupted.\n",
    "* Define the graph using nice scopes so the graph looks good in TensorBoard.\n",
    "* Add summaries to visualize the learning curves in TensorBoard.\n",
    "* Try tweaking some hyperparameters such as the learning rate or the mini-batch size and look at the shape of the learning curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start, we will add 4 more features to the inputs: ${x_1}^2$, ${x_2}^2$, ${x_1}^3$ and ${x_2}^3$. This was not part of the exercise, but it will demonstrate how adding features can improve the model. We will do this manually, but you could also add them using `sklearn.preprocessing.PolynomialFeatures`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_enhanced = np.c_[X_train,\n",
    "                         np.square(X_train[:, 1]),\n",
    "                         np.square(X_train[:, 2]),\n",
    "                         X_train[:, 1] ** 3,\n",
    "                         X_train[:, 2] ** 3]\n",
    "X_test_enhanced = np.c_[X_test,\n",
    "                        np.square(X_test[:, 1]),\n",
    "                        np.square(X_test[:, 2]),\n",
    "                        X_test[:, 1] ** 3,\n",
    "                        X_test[:, 2] ** 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what the \"enhanced\" training set looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+00,  -5.14696757e-02,   4.44198631e-01,\n",
       "          2.64912752e-03,   1.97312424e-01,  -1.36349734e-04,\n",
       "          8.76459084e-02],\n",
       "       [  1.00000000e+00,   1.03201691e+00,  -4.19741157e-01,\n",
       "          1.06505890e+00,   1.76182639e-01,   1.09915879e+00,\n",
       "         -7.39511049e-02],\n",
       "       [  1.00000000e+00,   8.67891864e-01,  -2.54827114e-01,\n",
       "          7.53236288e-01,   6.49368582e-02,   6.53727646e-01,\n",
       "         -1.65476722e-02],\n",
       "       [  1.00000000e+00,   2.88850997e-01,  -4.48668621e-01,\n",
       "          8.34348982e-02,   2.01303531e-01,   2.41002535e-02,\n",
       "         -9.03185778e-02],\n",
       "       [  1.00000000e+00,  -8.33439108e-01,   5.35056649e-01,\n",
       "          6.94620746e-01,   2.86285618e-01,  -5.78924095e-01,\n",
       "          1.53179024e-01]])"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_enhanced[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, next let's reset the default graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define the `logistic_regression()` function to create the graph. We will leave out the definition of the inputs `X` and the targets `y`. We could include them here, but leaving them out will make it easier to use this function in a wide range of use cases (e.g. perhaps we will want to add some preprocessing steps for the inputs before we feed them to the Logistic Regression model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_regression(X, y, initializer=None, seed=42, learning_rate=0.01):\n",
    "    n_inputs_including_bias = int(X.get_shape()[1])\n",
    "    with tf.name_scope(\"logistic_regression\"):\n",
    "        with tf.name_scope(\"model\"):\n",
    "            if initializer is None:\n",
    "                initializer = tf.random_uniform([n_inputs_including_bias, 1], -1.0, 1.0, seed=seed)\n",
    "            theta = tf.Variable(initializer, name=\"theta\")\n",
    "            logits = tf.matmul(X, theta, name=\"logits\")\n",
    "            y_proba = tf.sigmoid(logits)\n",
    "        with tf.name_scope(\"train\"):\n",
    "            loss = tf.losses.log_loss(y, y_proba, scope=\"loss\")\n",
    "            optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "            training_op = optimizer.minimize(loss)\n",
    "            loss_summary = tf.summary.scalar('log_loss', loss)\n",
    "        with tf.name_scope(\"init\"):\n",
    "            init = tf.global_variables_initializer()\n",
    "        with tf.name_scope(\"save\"):\n",
    "            saver = tf.train.Saver()\n",
    "    return y_proba, loss, training_op, loss_summary, init, saver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a little function to get the name of the log directory to save the summaries for Tensorboard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def log_dir(prefix=\"\"):\n",
    "    now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "    root_logdir = \"tf_logs\"\n",
    "    if prefix:\n",
    "        prefix += \"-\"\n",
    "    name = prefix + \"run-\" + now\n",
    "    return \"{}/{}/\".format(root_logdir, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's create the graph, using the `logistic_regression()` function. We will also create the `FileWriter` to save the summaries to the log directory for Tensorboard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 2 + 4\n",
    "logdir = log_dir(\"logreg\")\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "\n",
    "y_proba, loss, training_op, loss_summary, init, saver = logistic_regression(X, y)\n",
    "\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At last we can train the model! We will start by checking whether a previous training session was interrupted, and if so we will load the checkpoint and continue training from the epoch number we saved. In this example we just save the epoch number to a separate file, but in chapter 11 we will see how to store the training step directly as part of the model, using a non-trainable variable called `global_step` that we pass to the optimizer's `minimize()` method.\n",
    "\n",
    "You can try interrupting training to verify that it does indeed restore the last checkpoint when you start it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10001\n",
    "batch_size = 50\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "checkpoint_path = \"/tmp/my_logreg_model.ckpt\"\n",
    "checkpoint_epoch_path = checkpoint_path + \".epoch\"\n",
    "final_model_path = \"./my_logreg_model\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    if os.path.isfile(checkpoint_epoch_path):\n",
    "        # if the checkpoint file exists, restore the model and load the epoch number\n",
    "        with open(checkpoint_epoch_path, \"rb\") as f:\n",
    "            start_epoch = int(f.read())\n",
    "        print(\"Training was interrupted. Continuing at epoch\", start_epoch)\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        sess.run(init)\n",
    "\n",
    "    for epoch in range(start_epoch, n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = random_batch(X_train_enhanced, y_train, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, summary_str = sess.run([loss, loss_summary], feed_dict={X: X_test_enhanced, y: y_test})\n",
    "        file_writer.add_summary(summary_str, epoch)\n",
    "        if epoch % 500 == 0:\n",
    "            print(\"Epoch:\", epoch, \"\\tLoss:\", loss_val)\n",
    "            saver.save(sess, checkpoint_path)\n",
    "            with open(checkpoint_epoch_path, \"wb\") as f:\n",
    "                f.write(b\"%d\" % (epoch + 1))\n",
    "\n",
    "    saver.save(sess, final_model_path)\n",
    "    y_proba_val = y_proba.eval(feed_dict={X: X_test_enhanced, y: y_test})\n",
    "    os.remove(checkpoint_epoch_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we can make predictions by just classifying as positive all the instances whose estimated probability is greater or equal to 0.5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = (y_proba_val >= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97979797979797978"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97979797979797978"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEFCAYAAAAIZiutAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIAiCIPjx/wPPtlQ2WdIQ6gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112fee350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_idx = y_pred.reshape(-1) # a 1D array rather than a column vector\n",
    "plt.plot(X_test[y_pred_idx, 1], X_test[y_pred_idx, 2], 'go', label=\"Positive\")\n",
    "plt.plot(X_test[~y_pred_idx, 1], X_test[~y_pred_idx, 2], 'r^', label=\"Negative\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that's much, much better! Apparently the new features really helped a lot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try starting the tensorboard server, find the latest run and look at the learning curve (i.e., how the loss evaluated on the test set evolves as a function of the epoch number):\n",
    "\n",
    "```\n",
    "$ tensorboard --logdir=tf_logs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can play around with the hyperparameters (e.g. the `batch_size` or the `learning_rate`) and run training again and again, comparing the learning curves. You can even automate this process by implementing grid search or randomized search. Below is a simple implementation of a randomized search on both the batch size and the learning rate. For the sake of simplicity, the checkpoint mechanism was removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "  logdir: tf_logs/logreg-run-20170923043654/\n",
      "  batch size: 21\n",
      "  learning_rate: 0.00443037524522\n",
      "  training: .....................\n",
      "  precision: 0.979797979798\n",
      "  recall: 0.979797979798\n",
      "Iteration 1\n",
      "  logdir: tf_logs/logreg-run-20170923044400/\n",
      "  batch size: 75\n",
      "  learning_rate: 0.00178264971514\n",
      "  training: .....................\n",
      "  precision: 0.969696969697\n",
      "  recall: 0.969696969697\n",
      "Iteration 2\n",
      "  logdir: tf_logs/logreg-run-20170923044609/\n",
      "  batch size: 86\n",
      "  learning_rate: 0.00203228544324\n",
      "  training: .....................\n",
      "  precision: 0.969696969697\n",
      "  recall: 0.969696969697\n",
      "Iteration 3\n",
      "  logdir: tf_logs/logreg-run-20170923044801/\n",
      "  batch size: 87\n",
      "  learning_rate: 0.00449152382514\n",
      "  training: .....................\n",
      "  precision: 0.979797979798\n",
      "  recall: 0.979797979798\n",
      "Iteration 4\n",
      "  logdir: tf_logs/logreg-run-20170923045000/\n",
      "  batch size: 61\n",
      "  learning_rate: 0.0796323472178\n",
      "  training: .....................\n",
      "  precision: 0.980198019802\n",
      "  recall: 1.0\n",
      "Iteration 5\n",
      "  logdir: tf_logs/logreg-run-20170923045236/\n",
      "  batch size: 92\n",
      "  learning_rate: 0.000463425058329\n",
      "  training: .....................\n",
      "  precision: 0.912621359223\n",
      "  recall: 0.949494949495\n",
      "Iteration 6\n",
      "  logdir: tf_logs/logreg-run-20170923045420/\n",
      "  batch size: 74\n",
      "  learning_rate: 0.0477068184194\n",
      "  training: .....................\n",
      "  precision: 0.98\n",
      "  recall: 0.989898989899\n",
      "Iteration 7\n",
      "  logdir: tf_logs/logreg-run-20170923045637/\n",
      "  batch size: 58\n",
      "  learning_rate: 0.000169404470952\n",
      "  training: .....................\n",
      "  precision: 0.9\n",
      "  recall: 0.909090909091\n",
      "Iteration 8\n",
      "  logdir: tf_logs/logreg-run-20170923045928/\n",
      "  batch size: 61\n",
      "  learning_rate: 0.0417146119941\n",
      "  training: .....................\n",
      "  precision: 0.980198019802\n",
      "  recall: 1.0\n",
      "Iteration 9\n",
      "  logdir: tf_logs/logreg-run-20170923050211/\n",
      "  batch size: 92\n",
      "  learning_rate: 0.000107429229684\n",
      "  training: .....................\n",
      "  precision: 0.882352941176\n",
      "  recall: 0.757575757576\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "\n",
    "n_search_iterations = 10\n",
    "\n",
    "for search_iteration in range(n_search_iterations):\n",
    "    batch_size = np.random.randint(1, 100)\n",
    "    learning_rate = reciprocal(0.0001, 0.1).rvs(random_state=search_iteration)\n",
    "\n",
    "    n_inputs = 2 + 4\n",
    "    logdir = log_dir(\"logreg\")\n",
    "    \n",
    "    print(\"Iteration\", search_iteration)\n",
    "    print(\"  logdir:\", logdir)\n",
    "    print(\"  batch size:\", batch_size)\n",
    "    print(\"  learning_rate:\", learning_rate)\n",
    "    print(\"  training: \", end=\"\")\n",
    "\n",
    "    reset_graph()\n",
    "\n",
    "    X = tf.placeholder(tf.float32, shape=(None, n_inputs + 1), name=\"X\")\n",
    "    y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "\n",
    "    y_proba, loss, training_op, loss_summary, init, saver = logistic_regression(\n",
    "        X, y, learning_rate=learning_rate)\n",
    "\n",
    "    file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "    n_epochs = 10001\n",
    "    n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "    final_model_path = \"./my_logreg_model_%d\" % search_iteration\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            for batch_index in range(n_batches):\n",
    "                X_batch, y_batch = random_batch(X_train_enhanced, y_train, batch_size)\n",
    "                sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            loss_val, summary_str = sess.run([loss, loss_summary], feed_dict={X: X_test_enhanced, y: y_test})\n",
    "            file_writer.add_summary(summary_str, epoch)\n",
    "            if epoch % 500 == 0:\n",
    "                print(\".\", end=\"\")\n",
    "\n",
    "        saver.save(sess, final_model_path)\n",
    "\n",
    "        print()\n",
    "        y_proba_val = y_proba.eval(feed_dict={X: X_test_enhanced, y: y_test})\n",
    "        y_pred = (y_proba_val >= 0.5)\n",
    "        \n",
    "        print(\"  precision:\", precision_score(y_test, y_pred))\n",
    "        print(\"  recall:\", recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `reciprocal()` function from SciPy's `stats` module returns a random distribution that is commonly used when you have no idea of the optimal scale of a hyperparameter. See the exercise solutions for chapter 2 for more details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "nav_menu": {
   "height": "603px",
   "width": "616px"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
